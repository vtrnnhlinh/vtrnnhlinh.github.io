<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" xml:lang="en"><generator uri="https://jekyllrb.com/" version="4.4.1">Jekyll</generator><link href="https://vtrnnhlinh.github.io/feed.xml" rel="self" type="application/atom+xml"/><link href="https://vtrnnhlinh.github.io/" rel="alternate" type="text/html" hreflang="en"/><updated>2025-09-10T04:23:56+00:00</updated><id>https://vtrnnhlinh.github.io/feed.xml</id><title type="html">blank</title><subtitle>A simple logbook of Linh </subtitle><entry><title type="html">Aug 2025 Reading Log</title><link href="https://vtrnnhlinh.github.io/blog/2025/aug-2025-reading-log/" rel="alternate" type="text/html" title="Aug 2025 Reading Log"/><published>2025-09-03T02:15:00+00:00</published><updated>2025-09-03T02:15:00+00:00</updated><id>https://vtrnnhlinh.github.io/blog/2025/aug-2025-reading-log</id><content type="html" xml:base="https://vtrnnhlinh.github.io/blog/2025/aug-2025-reading-log/"><![CDATA[<h2 id="7-hoang-mạc-tarta---dino-buzzati">7. Hoang mạc Tarta - Dino Buzzati</h2> <p>To me, this book is <strong>an absolute masterpiece</strong>. About words and the art, it’s enough, not too fancy to be stunned, not too little to furrow my eyebrows. But it’s enough and balance, between the haunting beauty of the landscapes and the inner war of main protagonist. About the story, is it an epic story? No, or even it’s slightly a peaceful-but-hopeless tragedy. But why do I consider it a masterpiece? Cause I can see myself in it. It’s like someone bang the pagoda’s bell next to my ear. It shakes my soul, makes me can’t stop reading to finish within 2 days. I had to take a reflection to make myself different than the main character.</p> <p>Rate: :star::star::star::star::star: (Will re-read in English version later)</p> <h2 id="8-digital-minimalism---cal-newport">8. Digital Minimalism - Cal Newport</h2> <p>Cal Newport’s books are my favorite ones in non-fiction category, I quite a fan of his “Deep Work”. But with this book, I feel a wave of unsatistification. The value doesn’t make me feel inspired or motivated.</p> <p>Rate: :star::star::star:</p> <h2 id="9-the-practicing-mind---thomas-m-sterner">9. The Practicing Mind - Thomas M. Sterner</h2> <p>It’s a pretty short read but the writing is kinda good. The ideas in the book isn’t new, tbh. A similar book we can tell is <a href="https://vtrnnhlinh.github.io/blog/2025/july-25-reading-log/#4-deep-work---cal-newport">Deep Work by Cal Newport</a>. But the way the author explained, is soothing to read. The most valuable thing I learn from this book is: focusing on present, every will be better?</p> <p>Rate: :star::star::star::star:</p> <h2 id="10-hà-nội-ta-đánh-mỹ-giỏi---nguyễn-tuân">10. Hà Nội ta đánh Mỹ giỏi - Nguyễn Tuân</h2> <p>The first time I know about this work, it is kind of negative, as they believe he must be forced to write this. So when I approach this work, I have a kind of worry, wonder if Nguyễn’s figure in my heart will be broken.</p> <p>But that feeling vanishes as soon as I start reading. God knows if any force can break this frickin’ stubborn soul. He is himself, the man that can spend endless pages to yap about a single blossom to the ancient history, from the wet rice culture to the sentimental of spring days. He is himself, the one who can trashtalk, curse, yell at anyone he feels uncomfortable around.</p> <p>He is not brain-washed or whatever you can blame when he doesn’t act like you expected. He is more than some articles in “Vang bóng một thời” that he wrote in his young age. He is a serious, hardworking writer. He writes to express, or flex himself. And human is complex, not to mention an artist soul like him. More than the love for beauty, for travel, he is also a Vietnamese, a son of Hanoi. In the war, he is the one observes its cruelty and he is a victim of the war when he lost his beloved ones. So what did you expect from a straightforward person like him?</p> <p>Rate: :star::star::star::star::star:</p> <ol> <li>Mưa Đỏ - Chu Lai</li> </ol> <p>It’s unexpectedly good. I admit, I read it because of the trending movie. But you can’t deny that this is a good book. It makes me have a feeling, or have a related feeling to War and Peace by Leo Tolstoi. Of course it’s about the philosophy or massiveness of the work, you can’t compare to War and Peace like it. But the history background of the story, it is lively and gives me a delusion. The characters are diversity in their appearances and mindsets. The author’s mindset when explaining this battle is also similar to mine. Very gud.</p> <p>Rate: :star::star::star::star::star:</p>]]></content><author><name></name></author><category term="Journal-of-Sciences"/><category term="books"/><category term="english"/><summary type="html"><![CDATA[7. Hoang mạc Tarta - Dino Buzzati]]></summary></entry><entry><title type="html">Hallucination in NLG - Hallelujah yappin’ ya</title><link href="https://vtrnnhlinh.github.io/blog/2025/nlg-hallucination/" rel="alternate" type="text/html" title="Hallucination in NLG - Hallelujah yappin’ ya"/><published>2025-09-03T02:15:00+00:00</published><updated>2025-09-03T02:15:00+00:00</updated><id>https://vtrnnhlinh.github.io/blog/2025/nlg-hallucination</id><content type="html" xml:base="https://vtrnnhlinh.github.io/blog/2025/nlg-hallucination/"><![CDATA[<p>God knows why I researched about NLG Hallucination, but here you are, bro!</p> <p>I will use <a class="citation" href="#ji2023survey">(Ji et al., 2023)</a> and <a class="citation" href="#zhu2025can">(Zhu et al., 2025)</a> as the main source of this post. I may also cite other works but I can’t make sure I read all of them carefully, <em>ehem</em>. And as my current work is focus on text generation, so I will mainly yap about hallucination in this field.</p> <p>Okay. Get into the main dish. With the power of deep learning technologies, NLG (Natural Language Generation) develops rapidly. That also leads to the attention for limitations and risks increased, and they find out NLG models often generate nonsense, unfaithful text!</p> <p>And they call it <strong>hallucination</strong>.</p> <p><strong>Hallucination</strong> is a problem that we need to be careful with. Because it hinders performance, raises safe concerns, and leads to potential privacy violations. Like, just imagine <em>hallucination</em> in medical application AI :skull:.</p> <h2 id="categorization">Categorization</h2> <p>From an interesting work that maybe helpful for my work <a class="citation" href="#dziri2021neural">(Dziri et al., 2021)</a>, we can divide <em>hallucination</em> into 2 categories.</p> <ol> <li><strong>Intrinsic Hallucinations</strong>: the generated output <strong>contradicts</strong> the source content.</li> <li><strong>Extrinsic Hallucinations</strong>: the generated output <strong>can’t be verified</strong> from source content.</li> </ol> <h3 id="factuality-vs-faithfulness">Factuality vs Faithfulness</h3> <p>According to the work <a class="citation" href="#maynez2020faithfulness">(Maynez et al., 2020)</a>, and <a class="citation" href="#ji2023survey">(Ji et al., 2023)</a>, we should seperate <strong>factuality</strong> and <strong>faithfulness</strong> to provide more clear understanding.</p> <table> <thead> <tr> <th>Factuality</th> <th>Faithfulness</th> </tr> </thead> <tbody> <tr> <td>Consistent, truthful to <strong>source knowledge</strong></td> <td>Being actual or based on <strong>world knowledge</strong></td> </tr> </tbody> </table> <h2 id="contributors-to-hallucinations">Contributors to Hallucinations</h2> <h3 id="from-data">From Data</h3> <p>Collecting heuristic data creates mismatches between source and data, that leads to <em>hallucination</em>. And in big datasets, there are cases the examples are duplicated or similar, lead the model to favor generating repeats of memorized phrases.</p> <p>Another problem from data is some doesn’t have factual knowledge, like some datasets for chit-chat style. That leads to extrinsic hallucinations. In this case I am not sure it’s a bug or a feature.</p> <h3 id="from-training-and-inference">From Training and Inference</h3> <p>Even when your dataset has very little divergence, <em>hallucination</em> will find you in another way around, in the way you train and inference your model :evil:.</p> <p>First is maybe your encoder isn’t suitable? The encoder will turn your input text into meaningful representations, if the encoder learns wrong correlations between different parts of the training data, everything will drift away, fast.</p> <p>Then the decoder, what if the decoder attends the wrong part of encoded input source? Or some decoding strategy improves the generation diversity, like <em>TopK</em> sampling strategy is positively correlated with increased hallucination. This is a point we need to find a middle ground to balance between hallucination and answer quality.</p> <p>The <em>exposure bias</em>, or the discrepancy between training and inference is also a problem. It’s like you when studying and in exam. But I think this one can be improved through some techniques :sparkles:.</p> <p>Pre-trained models can prioritize parametric knowledge over the provided input that leads to hallucination. About this information, I wonder about fine-tuned models <em>thonk</em>.</p> <h2 id="metrics">Metrics</h2> <p>Thank you, this is very valuable section, I love it. Added FRANK (cite frank) and TRUE (cite true) to my collection to assess my model later. These have the effort to quantifying hallucination?</p> <p>One of the simplest approaches is to leverage <strong>lexical features (n-grams)</strong>. This will calculate overlap information and contradictions between generated and reference texts.</p> <p>NLG tasks can have many outputs from the same input (one-to-many mapping), so to simplify the evaluation setup, they only rely on the source text as sole reference.</p> <p><strong>Model-based</strong> metrics measure the hallucination degree in generated text.</p> <p><em>Information Extraction (IE)-based</em> use IE models to represent the knowledge in tuplet format then verify against tuplets extracted from source/reference.</p> <p><em>QA-based</em> works in 3 steps:</p> <ul> <li>Question generation (QG) model generates set of question-answer pairs</li> <li>Question answering (QA) model answers generated questions - become the reference</li> <li>Hallucination score calculates base on <strong>similarity</strong> of corresponding answers.</li> </ul> <p>The problems of these 2 approaches are similar, it depends on the accuracy of the models using to evaluate.</p> <p><em>Natural Language Inference (NLI)</em> metrics determines whether a “hypothesis” is true, false or undetermined. NLI-based approach seems more robust, but also has bad performance in abstractive summarization task.</p> <p><em>Faithfulness Classification Metrics</em> are constructed to improve from the NLI-based metrics. But I don’t understand how superior it is (yet).</p> <p><em>LM-based Metrics</em>. This method uses 2 language models.</p> <ul> <li>Unconditional LM - only trained on the <strong>target data</strong>.</li> <li>Conditional LM - trained on <strong>both source and target data</strong>.</li> </ul> <p><em>Human Evaluation</em> is still one of the most commonly used approaches as current automatic evaluation of hallucinations is still imperfect. Two main forms of human evaluation:</p> <ul> <li><strong>Scoring</strong>: human rate the hallucination level in a range</li> <li><strong>Comparing</strong>: Human compare output texts with baseline</li> </ul> <h2 id="hallucination-mitigation-methods">Hallucination Mitigation Methods</h2> <h3 id="data-related">Data-Related</h3> <ul> <li>Building a faithful dataset. You can use “rice-fuel machines” to write clean and faithful targets, another way is use model to generate data and instruct annotators to label.</li> <li>Clean Data Automatically. This approach suitable for case has low or moderate level of noise in original data.</li> <li>Augment Information. Help model has better semantic understanding, enforce a stronger alignment between inputs and outputs.</li> </ul> <h3 id="modeling-and-inference">Modeling and Inference</h3> <p>In my understanding, we can reduce the hallucination by specific (or tailor-made) encoder, attention and decoder strategy. This seems an interesting aspect to discover? :wink: Ahehe.</p> <p>About Training strategy, there are a lot of approaches, we can consider some famous one like Reinforcement Learning (RL), Multi-task Learning, etc etc. An another way to reduce hallucination while requires less training data is post-processing. Some of works follow <strong>generate-then-define strategy</strong>. They use SOTA models to get the results, then correct it my using small amount of automatically generated training data.</p> <hr/> <p>I plan to write longer but I think it’s long enough and I know enough to use in this topic, and I am afraid if I don’t publish now, I won’t have any motivations to finish like I planned. So here you are, a piece of my learning.</p>]]></content><author><name></name></author><category term="Linh-the-Engineer"/><category term="cse"/><category term="ml"/><category term="gom"/><category term="english"/><summary type="html"><![CDATA[in this post we will discover the world of hallucination in NLG]]></summary></entry><entry><title type="html">Ithya Magic Studies joins the gang</title><link href="https://vtrnnhlinh.github.io/blog/2025/ithya-in-system/" rel="alternate" type="text/html" title="Ithya Magic Studies joins the gang"/><published>2025-08-21T06:50:00+00:00</published><updated>2025-08-21T06:50:00+00:00</updated><id>https://vtrnnhlinh.github.io/blog/2025/ithya-in-system</id><content type="html" xml:base="https://vtrnnhlinh.github.io/blog/2025/ithya-in-system/"><![CDATA[<p>Hear me out! This one is peak, fr fr. It’s like the child of <a href="https://www.youtube.com/channel/UCSJ4gkVC6NrvII8umztf0Ow">lofi girl</a> and <a href="https://www.studytogether.com/">studytogether</a>. Even though there is a lot of space for improvement, but I believe the product is already solid and worth every penny. I drop the link here :point_down:</p> <blockquote> <p><a href="https://store.steampowered.com/app/3330250/Ithya_Magic_Studies/">Steam: Ithya Magic Studies</a></p> </blockquote> <hr/> <h2 id="what-do-i-like-about-it">What do I like about it?</h2> <p>First, the artstyle is very aesthetic :sparkles:. I love the cartoon 2D artstyle. It’s good for my one cell brain. 3D is heavier than necessary to an app for productivity.</p> <p>Second, the gamification motivates me to open my laptop instead of doom-scrolling my phone. I want to be a great mage, weeza!</p> <p>Third, various of scene makes me imagine every scene of my life fits with action happening on screen, that helps me a lot to focus on study.</p> <p>Finally, it fits perfectly with my current workstream! It contributes value to my current system, not being an useless addition that contributes nothing but duplicated features with other apps.</p> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/ithya_hours-480.webp 480w,/assets/img/ithya_hours-800.webp 800w,/assets/img/ithya_hours-1400.webp 1400w," type="image/webp" sizes="95vw"/> <img src="/assets/img/ithya_hours.jpg" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> <p>My current hours in this game, already surpass a lot of other games I played.</p> <h2 id="how-do-i-use-it">How do I use it?</h2> <p>For productivity, it has 3 main features: Timer, Tasks and Journal. The Journal feature is kinda useless, I only use it to reset the Task list. The Timer feature will make it duplicates with the Pomodoro timer on TickTick. I decide to use Stopwatch on TickTick to start a big task, and with Ithya, I divide it into smaller tasks and use Pomodoro timer of Ithya. Listing out subtasks in Ithya is less frictional than on Ticktick due to its simplicity nature.</p> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/ithya_tasks-480.webp 480w,/assets/img/ithya_tasks-800.webp 800w,/assets/img/ithya_tasks-1400.webp 1400w," type="image/webp" sizes="95vw"/> <img src="/assets/img/ithya_tasks.jpg" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> <p>An example of how I use this game.</p> <p>The music in this game/app is phenomenal, remember to wear your earphones when using it! The rain effect and the lofi is very calming and inspirational. When studying, I set to scene she studies at home or at library, then in break time I move to nature scene. I enjoy fantasizing myself in that lil cute girl!</p> <h2 id="things-can-be-improved">Things can be improved</h2> <p>The Journal feature is suck. Luckily I use Ticktick as main system and this is just a small fantasy motivating myself or I can scream. Heard that they will have a patch update to improve this soon</p> <p>Some statistic and chart will be satistifying and nice. More customization to the character like hair, skin color will be lovely but not necessary :laughing:</p> <hr/> <p>So that is all for the day!</p>]]></content><author><name></name></author><category term="Journal-of-Sciences"/><category term="nerdies"/><category term="english"/><summary type="html"><![CDATA[my new recommend tool for studying]]></summary></entry><entry><title type="html">Đất nước trọn niềm vui, Đăng Dương và chuyện xưa</title><link href="https://vtrnnhlinh.github.io/blog/2025/dat-nuoc-tron-niem-vui/" rel="alternate" type="text/html" title="Đất nước trọn niềm vui, Đăng Dương và chuyện xưa"/><published>2025-08-17T16:55:00+00:00</published><updated>2025-08-17T16:55:00+00:00</updated><id>https://vtrnnhlinh.github.io/blog/2025/dat-nuoc-tron-niem-vui</id><content type="html" xml:base="https://vtrnnhlinh.github.io/blog/2025/dat-nuoc-tron-niem-vui/"><![CDATA[<p>Dạo này mình hay bật đi bật lại Đất nước trọn niềm vui của Đăng Dương, hát trong chương trình Tổ quốc trong tim. Không chỉ nghe, mình còn thích nhìn Đăng Dương hát lúc đó, ánh mắt lấp lánh ánh sao đêm. Có lẽ cả mình và chú ấy, trong khoảnh khắc đấy, đều hạnh phúc cho dòng nhạc mình yêu thương được khán giả đại chúng đón nhận nồng nhiệt.</p> <h2 id="từ-màu-hoa-đỏ">Từ Màu hoa đỏ</h2> <blockquote> <p>“…Dòng tên anh khắc vào đá núi</p> <p>Mây ngàn hoá bóng cây che…”</p> </blockquote> <p>Số lần mình rơm rớm nước mắt khi nghe bài này có lẽ không nhớ nổi, mình nhớ mình biết tới nó từ hồi lớp 5, 6 gì đấy chăng? Giọng Trọng Tấn lúc đấy đối với mình, đẹp và tình cảm nhất trên đời. Bây giờ mình không còn thấy giọng Trọng Tấn đẹp nhất, nhưng vẫn là một thứ gì đó, nếu theo như truyện Tàu thì chính là “bạch nguyệt quang” hẹ hẹ.</p> <p>Tới tận rất nhiều năm sau này, mình mới biết bài hát viết về cuộc chiến nào.</p> <h2 id="tới-nhạc-đỏ">Tới nhạc đỏ</h2> <p>Những năm tiếp theo, có năm mình là người chìm đắm vào Trịnh Công Sơn, có năm là những giai điệu USUK mà mình chẳng hiểu được lời, nhưng cũng có những ngày tháng, mình đã sống hết mình với nhạc đỏ. Mình chết mê chết mệt giọng hát của cô Thu Hiền, ôi mình nghĩ, nếu mình mà là đờn ông sống giữa đời, mừn sẽ muốn cưới cô ấy. Còn chú Kiều Hưng, mình có thể thích rất nhiều ca sĩ nam, nhưng chưa có ai có chất giọng khiến mình nghĩ “mình muốn cưới một người có giọng như vậy làm chồng”. Giọng của chú, chẳng thể dùng những người ta hay nói về giọng nam nhạc đỏ như “thép, lửa”. Đối với mình, giọng của chú như hương lúa ôm lấy tâm hồn người Việt. Mềm mại, nhẹ nhàng, tình cảm nhưng vững chắc vô cùng.</p> <blockquote> <p>“Rạo rực niềm vui, nhớ về thăm Mẹ</p> <p>Rộn ràng bàn chân, đường quê mong nhớ…”</p> </blockquote> <h2 id="đất-nước-trọn-niềm-vui">Đất nước trọn niềm vui</h2> <p>Một đêm nhạc đỏ ở sân Mỹ Đình, 50 nghìn khán giả? Một điều không tưởng ấy vậy mà lại thành hiện thực. Âm thanh, ánh sáng đều chuẩn chỉnh cả. Và khán giả thì nhiệt vô cùng.</p> <p>Ngày hôm ấy, Đăng Dương, một con người theo đuổi giấc mơ “chính ca” được lĩnh xướng 50 nghìn người. Có lẽ trong những giấc mơ xa xăm nhất, chưa chắc chú ấy đã dám mơ tới điều đấy. Nhà hát lớn, nơi vẫn được coi là thánh địa âm nhạc Việt Nam, mình bỗng thấy cũng chỉ tới thế mà thôi.</p> <p>Niềm hạnh phúc của người nghệ sĩ chạm tới mình qua chiếc màn hình 16 inch, để mình dành 2 3 tiếng đồng hồ ngồi tải nhạc, để thỉnh thoảng nghe lại dàn đồng ca và một giọng hát của tài năng và sự tận hiến.</p>]]></content><author><name></name></author><category term="Stories-of-Culture"/><category term="nhạc"/><category term="vietnamese"/><summary type="html"><![CDATA[ngẫu nhiên về nhạc đỏ]]></summary></entry><entry><title type="html">Obsidian Tour - August 2025</title><link href="https://vtrnnhlinh.github.io/blog/2025/obsidian-aug-2025/" rel="alternate" type="text/html" title="Obsidian Tour - August 2025"/><published>2025-08-12T06:50:00+00:00</published><updated>2025-08-12T06:50:00+00:00</updated><id>https://vtrnnhlinh.github.io/blog/2025/obsidian-aug-2025</id><content type="html" xml:base="https://vtrnnhlinh.github.io/blog/2025/obsidian-aug-2025/"><![CDATA[<p>It was a long time since I start using Obsidian again, only when I recognize that I can install Obsidian on my company laptop without admin rights :skull:. I decide to give myself a fresh start, let check out what we will install and take it cool :sunglasses:.</p> <h2 id="theme">Theme</h2> <p>My choice is <strong>gruvbox</strong>, always <strong>gruvbox</strong>, <strong>gruvbox</strong> is da bezt.</p> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/gruvbox_obsidian-480.webp 480w,/assets/img/gruvbox_obsidian-800.webp 800w,/assets/img/gruvbox_obsidian-1400.webp 1400w," type="image/webp" sizes="95vw"/> <img src="/assets/img/gruvbox_obsidian.jpg" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> <p>My gruvbox theme on my Arch 😆</p> <p>There are a lot of great great choices about themes on Obsidian, but keep in mind to make it simple or you can be overwhelmed.</p> <h2 id="default-settings">Default Settings</h2> <p>First thing to do ever when you use Obsidian: <code class="language-plaintext highlighter-rouge">Files &amp; Links &gt; Automatically update internal links: ON</code></p> <p>Then check out the Daily Note and prepare the template. You don’t need a fancy one, but focus on what will be meaningful to you. Like mine I need a reflection on what I should do.</p> <p>I avoid creating too much folders, as we can structure the notes through tags and links. Why? I believing creating too much folders will make friction to my creating notes as I have to choose which folder I should put the note on. Without folders and only tags, I can use shortcut to quickly create notes, and I can apply templates to have pre-fined tags and structure for each specialised note. I have 2 folders, one is for <strong>Templates</strong> and one is for <strong>Daily</strong> as I can automate Daily folder.</p> <h2 id="community-plugins">Community Plugins</h2> <h3 id="dataview">Dataview</h3> <p>First one is <strong>Dataview</strong>, I use this to have an overview for my reading list. The useful resource is <a href="https://blacksmithgu.github.io/obsidian-dataview/resources/examples/">Examples - Dataview</a>.</p> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/dataviewjs_obsidian-480.webp 480w,/assets/img/dataviewjs_obsidian-800.webp 800w,/assets/img/dataviewjs_obsidian-1400.webp 1400w," type="image/webp" sizes="95vw"/> <img src="/assets/img/dataviewjs_obsidian.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> <p>I use Dataview to tracking my books like this.</p> <h3 id="spaced-repetition">Spaced Repetition</h3> <p>Second one is <strong>Spaced Repetition</strong>. This plugin makes Obsidian more lively and more interactive. With this plugin, you can review knowledge easier without using a seperated flashcard app like Anki or Quizlet.</p> <p>Some recommended settings by me:</p> <ul> <li><strong>Cloze</strong>: Use <code class="language-plaintext highlighter-rouge">Convert ==highlights== to clozes</code> setting. Bold settings can be messy because sometimes you don’t intently want the bold to be cloze. Using curly brackets is the default Cloze setting on Anki.</li> <li><strong>Inline flashcard</strong>: I use <code class="language-plaintext highlighter-rouge">;</code> instead of <code class="language-plaintext highlighter-rouge">:</code> cause sometimes you don’t mean to make flashcard when using <code class="language-plaintext highlighter-rouge">:</code>. <code class="language-plaintext highlighter-rouge">;</code> is more rarely used and you have clearly intention when using it making flashcards.</li> <li><strong>Multiline flashcard</strong>: Because of multiline flashcard’s format, when <code class="language-plaintext highlighter-rouge">?</code> must lies in a seperate line. I have no problem using it.</li> </ul> <p>I don’t use <strong>Notes</strong> feature, I find it is not effective and passive.</p> <h3 id="tag-wrangler">Tag Wrangler</h3> <p>Tags is a powerful tool of Obsidian, and <strong>Tag Wrangler</strong> is the one saves your tags life. It will help your life easier to modify your tags in bulk or enhance searching with tags.</p> <h3 id="chronology">Chronology</h3> <p>Final one is <strong>Chronology</strong>, if you search “Calendar” on Obsidian Community Plugin page, it won’t be so impressive. But it’s my always first choice for Calendar on Obsidian. I love its heatmap, very aesthetic :sparkles: And I can easily search or trace back the notes I created or modified that day.</p> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/chronology_obsidian-480.webp 480w,/assets/img/chronology_obsidian-800.webp 800w,/assets/img/chronology_obsidian-1400.webp 1400w," type="image/webp" sizes="95vw"/> <img src="/assets/img/chronology_obsidian.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> <p>Chronology in my Obsidian.</p> <hr/> <p>Will update when I have some dramatic change!</p>]]></content><author><name></name></author><category term="Journal-of-Sciences"/><category term="nerdies"/><category term="english"/><summary type="html"><![CDATA[my obsidian theme and setup at August 2025]]></summary></entry><entry><title type="html">GraphRAG and Linh - theory and practice</title><link href="https://vtrnnhlinh.github.io/blog/2025/graphrag-theory-and-practice/" rel="alternate" type="text/html" title="GraphRAG and Linh - theory and practice"/><published>2025-08-11T10:50:00+00:00</published><updated>2025-08-11T10:50:00+00:00</updated><id>https://vtrnnhlinh.github.io/blog/2025/graphrag-theory-and-practice</id><content type="html" xml:base="https://vtrnnhlinh.github.io/blog/2025/graphrag-theory-and-practice/"><![CDATA[<p>This will be a mixture of theory and real-life experience. When I type this line, god knows what I am doing. Unlike previous times, I jump into doing immediately like blind in the darkness, even though I made progress and basically <em>it runs!</em>. But I feel like I am missing a lot of powerful points in this concept, so I write this post, to force myself systemize the <em>shiet</em> I am doing.</p> <h2 id="the-theory-and-the-idea">The Theory and The Idea</h2> <p><strong>GraphRAG</strong> is the work of Microsoft <a class="citation" href="#edge2024local">(Edge et al., 2024)</a>, it can be described like below:</p> <pre><code class="language-mermaid">graph TD
    A[🤖 Use LLM to Construct Knowledge Graph from Data/Text] --&gt; B[🗂 Partition Graph into Hierarchical Communities]
    B --&gt; C[📝 Use LLM to Generate Summaries for Each Community]
    C --&gt; D[📦 Store Community Summaries in Vector Store]
    D --&gt; E[❓ Receive User Query]
    E --&gt; F[🔍 Retrieve Relevant Community Summaries via Semantic Search]
    F --&gt; G[🗺 Map-Reduce Reasoning: Map → Process Each Summary Independently]
    G --&gt; H[🧠 Reduce → Aggregate &amp; Refine Answers]
    H --&gt; I[✅ Return Final Answer to User]
    
    I --&gt;|Feedback/Refinement| A
</code></pre> <p>To me, the hardest point of this work is graphing the knowledge graph, which is heavier about the technique, not the idea.</p> <h2 id="ramblin-ramblin">ramblin’ ramblin’</h2> <p>In my mindset, RAG has 3 steps: prepare the database, retrieve the data and reasoning with the data. This post only shares 2 first step, as the last step maybe involves other’s work. I will talk vaguely about last one in the <strong>retrievin’ the graph</strong> section.</p> <h3 id="shapin-the-graph">shapin’ the graph</h3> <p>At this very moment, I have my graph already~, we use <a href="https://neo4j.com/">neo4j</a> to become our graph database service.</p> <p>I use <code class="language-plaintext highlighter-rouge">localhost</code>, virgin uses cloud service, chad uses localhost :wink:</p> <p>We will show final result first, to show some aesthetic :sparkles:</p> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/neo4j_graph-480.webp 480w,/assets/img/neo4j_graph-800.webp 800w,/assets/img/neo4j_graph-1400.webp 1400w," type="image/webp" sizes="95vw"/> <img src="/assets/img/neo4j_graph.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/neo4j_nodes-480.webp 480w,/assets/img/neo4j_nodes-800.webp 800w,/assets/img/neo4j_nodes-1400.webp 1400w," type="image/webp" sizes="95vw"/> <img src="/assets/img/neo4j_nodes.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> <p>My Knowledge Graph and nodes on <code class="language-plaintext highlighter-rouge">neo4j</code></p> <p>To do this, I am inspired by <code class="language-plaintext highlighter-rouge">edc</code> <a class="citation" href="#zhang2024extract">(Zhang &amp; Soh, 2024)</a> to extract the information step-by-step. I create a simpler python file to run as modifying other code is still over of my current abilities. There are some problems like wrong variable names as I use a general model like <a href="https://huggingface.co/Qwen/Qwen3-8B"><code class="language-plaintext highlighter-rouge">Qwen3-8B</code></a>. It automatically fixed the variable to make it more “sense”. I don’t apply the usual process, like I didn’t have the schema file even though I define something similar to it.</p> <p>Yap yap yap bla bla bla. There are suggestions that <code class="language-plaintext highlighter-rouge">neo4j</code> have native supports to shape a Knowledge Graph, but I wonder if it’s applicable for unprocessed data like what I was working at.</p> <h3 id="retrievin-the-graph">retrievin’ the graph</h3> <p>The main tools to use in this part is <code class="language-plaintext highlighter-rouge">langchain</code> and <code class="language-plaintext highlighter-rouge">chromadb</code>. We use <code class="language-plaintext highlighter-rouge">langchain</code> functions to generate the suitable Cypher command fetching data from <code class="language-plaintext highlighter-rouge">neo4j</code> database. <code class="language-plaintext highlighter-rouge">chromadb</code> is used to saved retrieved data, help modularizing the pipeline.</p> <p>Here is the basic workflow:</p> <pre><code class="language-mermaid">graph TD
    A[❓ User Question] --&gt; B[📝 Build Prompt with Schema &amp; Examples]
    B --&gt; C[🤖 LLM Generates Cypher Query]
    C --&gt; D[🔍 Sanitize &amp; Validate Query]
    D --&gt; E[🔗 Execute Query in Neo4j]
    E --&gt; F[📥 Get Results]
    F --&gt; G[💽 Store in ChromaDB]
</code></pre> <p>The challenges of this part is the suitable Cypher example to help the LLM generate suitable Cypher command with the input. I use <code class="language-plaintext highlighter-rouge">SemanticSimilarityExampleSelector</code> but god knows which method is more effective in my case. Currently the result isn’t so stable. Still needs to figure out because of stupid model or too little examples.</p> <p>This is the workflow of final stage:</p> <pre><code class="language-mermaid">graph TD
    A[❓ Input Question] --&gt; B[🔍 Retrieve Relevant Data from ChromaDB]
    B --&gt; C[📚 Combine Retrieved Data with Knowledge Base]
    C --&gt; D[🤖 Reasoning / Generate Answer]
    D --&gt; E[✅ Output Final Answer]
</code></pre> <hr/> <p>Latest note: It seems I am missing a lot of powerful tools, will figure out to apply!</p>]]></content><author><name></name></author><category term="Linh-the-Engineer"/><category term="cse"/><category term="ml"/><category term="gom"/><category term="english"/><summary type="html"><![CDATA[in this post I am on my way to battle with the datasets]]></summary></entry><entry><title type="html">Graph-of-Models - Literature Review 4 - embracing the KGs</title><link href="https://vtrnnhlinh.github.io/blog/2025/gom-literature-review-3/" rel="alternate" type="text/html" title="Graph-of-Models - Literature Review 4 - embracing the KGs"/><published>2025-08-07T02:15:00+00:00</published><updated>2025-08-07T02:15:00+00:00</updated><id>https://vtrnnhlinh.github.io/blog/2025/gom-literature-review-3</id><content type="html" xml:base="https://vtrnnhlinh.github.io/blog/2025/gom-literature-review-3/"><![CDATA[<p>After the last post reflecting on my actions in battling with datasets, I find out it will be not effective in large-scale. So here I am, in the light of the day, digging <strong>Knowledge Graph (KGs)</strong> again.</p> <h2 id="what-is-it-now">What is it now?</h2> <p>To save time and effort, as if applicable to my real-life job, training models isn’t my sh*t, so I have to find easiest way for me to save resources and energy. I plan to use <a href="https://www.kaggle.com/">Kaggle</a> to train my models. Because the focus of my work is isn’t in the power of models but how they graph and connect all together.</p> <p>But my current focus will be about <strong>Natural Language Processing (NLP)</strong> to processing the datasets and the <strong>Knowledge Graph (KGs)</strong> as the dataframe.</p> <h2 id="embracin-kgs">Embracin’ KGs</h2> <p><strong>Knowledge Graph</strong> <a class="citation" href="#hogan2021knowledge">(Hogan et al., 2021)</a>, nodes represents <strong>entities</strong>, edges represents <strong>relations</strong>. There are some graph data models commonly used in practice, we will see~</p> <h3 id="directed-edge-labelled-graphs">Directed edge-labelled graphs</h3> <p>Another name is <strong>multi-relational graph</strong>. Defined by a set of nodes and a set of directed labelled edges. Using this data model offers <strong>flexibility</strong> for integrating new sources of data.</p> <p>Standardized data model of this type is <strong>Resource Description Framework (RDF)</strong>. <strong>RDF</strong> defines different types of nodes:</p> <ul> <li><strong>Internationalized Resource Identifiers (IRIs)</strong>: global identification of entities on the Web</li> <li><strong>literals</strong>: string</li> <li><strong>integers, dates,…</strong></li> <li><strong>blank nodes</strong>: anonymous nodes</li> </ul> <h3 id="heterogeneous-graphs">Heterogeneous graphs</h3> <p>This type of graph is a graph where each node and edge are flexible. Different types of nodes can connect directly to each other (?). I hope my understanding is fit.</p> <h3 id="property-graphs">Property graphs</h3> <p>This type can provide additional flexibility when modelling more complex relations. The set will be like <code class="language-plaintext highlighter-rouge">property-value</code> and <code class="language-plaintext highlighter-rouge">label</code> associated with both nodes and edges.</p> <h3 id="graph-dataset">Graph dataset</h3> <p>This one consists a set of <strong>named graphs</strong> and <strong>default graph</strong>. Default graph is a graph <strong>without an ID</strong>. This will help in <strong>Linked Data</strong>. Seems very interesting.</p> <hr/> <p>As when I publish this post, I already get past the Literature Review part and already have my own KG, so I have no motivations to get further and finish this post wholly :skull: But I think these are already enough to cover basic information about KG, if you want to get further, get in practicing :wink:</p>]]></content><author><name></name></author><category term="Linh-the-Engineer"/><category term="cse"/><category term="ml"/><category term="gom"/><category term="english"/><summary type="html"><![CDATA[in this post I reflect my understanding in shaping the KGs]]></summary></entry><entry><title type="html">July 2025 Reading Log</title><link href="https://vtrnnhlinh.github.io/blog/2025/july-25-reading-log/" rel="alternate" type="text/html" title="July 2025 Reading Log"/><published>2025-08-04T06:30:00+00:00</published><updated>2025-08-04T06:30:00+00:00</updated><id>https://vtrnnhlinh.github.io/blog/2025/july-25-reading-log</id><content type="html" xml:base="https://vtrnnhlinh.github.io/blog/2025/july-25-reading-log/"><![CDATA[<h2 id="4-deep-work---cal-newport">4. Deep Work - Cal Newport</h2> <p>The book is still solid and thoughtful, but not stunning like the first time I read it.</p> <p>I am grateful that I finished it in 2 days. It gives me some more aspects as now I am already going to work instead of a student like before.</p> <p>Rate: :star::star::star::star:</p> <h2 id="5-the-little-prince----antoine-de-saint-exupéry">5. The Little Prince - Antoine de Saint-Exupéry</h2> <p>The book of my heart. The masterpiece of my life. To me, the philosophy of love in this book deeply affects my definition of love and more.</p> <p>More than love, it’s friendship, life and your value.</p> <p>Rate: :star::star::star::star::star:</p> <h2 id="6-nhật-ký-đặng-thùy-trâm---đặng-thùy-trâm">6. Nhật ký Đặng Thùy Trâm - Đặng Thùy Trâm</h2> <p>There is one thing I don’t like about this book, is they compare it to “The Diary of a Young Girl”. I believe this stand out as its own value, of a young petty bourgeoisie, dare to fight, dare to love, dare to dream about communism. I didn’t read that book yet, but I don’t like how they compare them.</p> <p>Rate: :star::star::star::star:</p>]]></content><author><name></name></author><category term="Journal-of-Sciences"/><category term="books"/><category term="english"/><summary type="html"><![CDATA[4. Deep Work - Cal Newport]]></summary></entry><entry><title type="html">codeLynn - fantasies and MLOps</title><link href="https://vtrnnhlinh.github.io/blog/2025/codeLynn-0/" rel="alternate" type="text/html" title="codeLynn - fantasies and MLOps"/><published>2025-07-21T08:00:00+00:00</published><updated>2025-07-21T08:00:00+00:00</updated><id>https://vtrnnhlinh.github.io/blog/2025/codeLynn-0</id><content type="html" xml:base="https://vtrnnhlinh.github.io/blog/2025/codeLynn-0/"><![CDATA[<p>Ehem, I am here, in the cold light of the day~</p> <p>Now I am in the stage that studying on <a href="https://www.coursera.org/">Coursera</a> feels bland and isn’t impressive anymore.</p> <p>I heard the term “MLOps” on Threads and it stirred my mind in the weekend. Then now, I decide to make an AI chatbot product, serving for my needs.</p> <p>Unlike <a href="https://vtrnnhlinh.github.io/blog/tag/gom/">Graph-of-Models</a> which is focus on researching and propose method, <strong>codeLynn</strong> focuses on bringing the art into deployment.</p> <h2 id="definition-of-codelynn">Definition of codeLynn</h2> <p>I want to create a virtual self of mine. You know <a href="https://character.ai/">c.ai</a>, yes, I want to do something similar to this :&gt; But it will have my tone and my personalities.</p> <p>Seems scary and funny at the same time, hopefully it won’t be unhinged like me.</p> <p>Why I use this? Maybe just need a friend shares the same brain frequency. Sometimes, there are thoughts and ideas I don’t dare to share to human, because it can be triggering.</p> <p>I want to be open more about myself, and nothing better than an AI agent that accumulate more knowledge than mine, know about me and don’t judge me.</p> <p>It should be an AI system have general knowledge that have fine-tuned modules in coding, mathematics and languages like German or Latin.</p> <p>Its tone and persona should be like <em>me</em>. This part maybe will be RLHF <a class="citation" href="#ouyang2022training">(Ouyang et al., 2022)</a>. The chatbot will be text-focused, I don’t think about image generation or voice chat.</p> <h2 id="what-is-mlops">What is MLOps?</h2> <p><a title="Cmbreuel, CC BY-SA 4.0 &lt;https://creativecommons.org/licenses/by-sa/4.0&gt;, via Wikimedia Commons" href="https://commons.wikimedia.org/wiki/File:ML_Ops_Venn_Diagram.svg"><img width="512" alt="ML Ops Venn Diagram" src="https://upload.wikimedia.org/wikipedia/commons/thumb/1/1b/ML_Ops_Venn_Diagram.svg/512px-ML_Ops_Venn_Diagram.svg.png?20210725212146"/></a></p> <p><strong>MLOps</strong> is a paradigm, an engineering practice that is a mix of ML, software engineering and data engineering. It’s the procedure to make our ML models from <strong>development</strong> stage get into <strong>production</strong> in a consistent and reliable manner <a class="citation" href="#stone2025navigating">(Stone et al., 2025)</a>.</p> <p>In a full cycle of MLOps, there are a lot of stages like image below. In reality we won’t need to implement some steps as our scale is far smaller.</p> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/MLOps-lifecycle-dev-480.webp 480w,/assets/img/MLOps-lifecycle-dev-800.webp 800w,/assets/img/MLOps-lifecycle-dev-1400.webp 1400w," type="image/webp" sizes="95vw"/> <img src="/assets/img/MLOps-lifecycle-dev.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> <p>MLOps lifecycle <a class="citation" href="#ouyang2022training">(Ouyang et al., 2022)</a>.</p> <p>My work will use <a href="https://www.kubeflow.org/">Kubeflow</a> as the core spine.</p> <figure> <picture> <source class="responsive-img-srcset" srcset="https://www.kubeflow.org/docs/started/images/kubeflow-architecture.drawio.svg" sizes="95vw"/> <img src="https://www.kubeflow.org/docs/started/images/kubeflow-architecture.drawio.svg" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> <p>Kubeflow architecture (Source: <a href="https://www.kubeflow.org/docs/started/architecture/">Kubeflow</a>).</p> <hr/> <p>I will update in the next post more things about datasets and models :laughing:</p>]]></content><author><name></name></author><category term="Linh-the-Engineer"/><category term="cse"/><category term="ml"/><category term="codeLynn"/><category term="english"/><summary type="html"><![CDATA[in this post I will land another project]]></summary></entry><entry><title type="html">Graph-of-Models - a journey of a thousand miles begins with a single step</title><link href="https://vtrnnhlinh.github.io/blog/2025/gom-action-0/" rel="alternate" type="text/html" title="Graph-of-Models - a journey of a thousand miles begins with a single step"/><published>2025-07-15T04:30:00+00:00</published><updated>2025-07-15T04:30:00+00:00</updated><id>https://vtrnnhlinh.github.io/blog/2025/gom-action-0</id><content type="html" xml:base="https://vtrnnhlinh.github.io/blog/2025/gom-action-0/"><![CDATA[<p>Hohoho, finally, I did something instead of talking :laughing:</p> <p>There are 2 main achievements I will present in this post. First, I calculated the <strong>Cosine Similarity</strong> <a class="citation" href="#gunawan2018implementation">(Gunawan et al., 2018; Dehak et al., 2010)</a>. Second, I have attempted to fine-tuned first <code class="language-plaintext highlighter-rouge">miniModel_1</code>, even though the result isn’t so good, but still.</p> <p>I can show Jupyter Notebook and such in this blog, but I won’t do that here, at least today. I believe the engineering mindset is more worth sharing and the code is already in GitHub repo.</p> <p>GitHub repository (just in case): <a href="https://github.com/vtrnnhlinh/Graph-of-Models/tree/main">vtrnnhlinh/Graph-of-Models</a></p> <h2 id="what-i-did">What I did?</h2> <p>I will try to explain from the idea, purpose to implement.</p> <h3 id="repo-structure">Repo Structure</h3> <p>The current code structure of this project is something like this:</p> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>.
├── datasets
│   ├── dataset_1
│   ├── dataset_2
│   ├── dataset_3
├── edges_calculation
│   ├── cosine_similarity
│   │   └── results
│   └── jaccard_index
├── environment.yml
├── graph-of-models
├── graph_visualization
│   ├── cosine_similarity
│   └── jaccard_index
├── inference
├── LICENSE
├── Models
└── README.md
</code></pre></div></div> <p>The workflow is divided into different components (folders). The output of previous component will be saved to suitable formats like <code class="language-plaintext highlighter-rouge">.parquet</code> or <code class="language-plaintext highlighter-rouge">.csv</code>. This will help saving time and easier debugging.</p> <p>The newest structure you can visit the GitHub repo.</p> <p>The <code class="language-plaintext highlighter-rouge">datasets</code> and <code class="language-plaintext highlighter-rouge">Models</code> contents are in <code class="language-plaintext highlighter-rouge">.gitignore</code> due to its mass size. Read <code class="language-plaintext highlighter-rouge">README.md</code> of each folder to setup yourself if you want to re-enact my work.</p> <h3 id="preprocessing-data">Preprocessing Data</h3> <p>I use <code class="language-plaintext highlighter-rouge">.parquet</code> as the default dataset filetype to process in this project. Why? Because it’s effective for large dataset, which is necessary for fine-tuned our models <a class="citation" href="#ivanov2020impact">(Ivanov &amp; Pergolesi, 2020)</a>.</p> <p>That means you need a code file to do the conversion. It’s not so hard to implement. With my current need, I only need to convert from <code class="language-plaintext highlighter-rouge">.csv</code> to <code class="language-plaintext highlighter-rouge">.parquet</code>.</p> <p>To calculate <strong>Cosine Similarity</strong> and <strong>Jaccard Index</strong>, we need to have a core column sharing the same name. Our datasets are all in food-related topic, so I choose <code class="language-plaintext highlighter-rouge">ingredients</code> as the core.</p> <p>That makes us have to manually pre-process the data by convert the suitable column in each dataset to <code class="language-plaintext highlighter-rouge">ingredients</code>. The detail code I used is in <code class="language-plaintext highlighter-rouge">edges_calculation/general_preprocess.ipynb</code> file.</p> <h3 id="cosine-similarity-preprocessing-and-calculation">Cosine Similarity Preprocessing and Calculation</h3> <p>To calculate the <strong>Cosine Similarity</strong>, we need to vectorize the datasets.</p> <p>That makes us need to combine all subdatasets of each <code class="language-plaintext highlighter-rouge">miniModel</code>’s dataset into one big <code class="language-plaintext highlighter-rouge">.parquet</code> file: <code class="language-plaintext highlighter-rouge">dataset_N_cos.parquet</code>.</p> <p>Then we will clean the dataset and vectorize it, compute the average <strong>Cosine Similarity</strong>, export to <code class="language-plaintext highlighter-rouge">.csv</code> file and voila~.</p> <h3 id="cosine-similarity-graph-visualization">Cosine Similarity Graph Visualization</h3> <p>We will have a seperate module to visualize the graph. Importing the <code class="language-plaintext highlighter-rouge">.csv</code> file from <strong>Cosine Similarity Calculation</strong> with the edges are the average cosine similarity value, nodes are the datasets.</p> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/cosine_similarity_graph_0-480.webp 480w,/assets/img/cosine_similarity_graph_0-800.webp 800w,/assets/img/cosine_similarity_graph_0-1400.webp 1400w," type="image/webp" sizes="95vw"/> <img src="/assets/img/cosine_similarity_graph_0.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> <p>The first <strong>Cosine Similarity</strong> result we have.</p> <h3 id="fine-tune-minimodel_1">Fine-tune miniModel_1</h3> <p>To avoid environment conflicts, we will create a seperate conda environment to fine-tune this model.</p> <p>I use <code class="language-plaintext highlighter-rouge">LoRA</code> to train <code class="language-plaintext highlighter-rouge">Qwen3-0.6B</code> model for <code class="language-plaintext highlighter-rouge">miniModel_1</code>. The dataset and the model is small, but it still seems too much with my laptop.</p> <p>The result is the fine-tuned model seems dumb. After revision, I see I only take a column in my dataset to train, which is lacking a lot of datas.</p> <h2 id="some-reflections">Some reflections</h2> <ul> <li>The <strong>Cosine Similarity</strong> result seems suspicious. I actually expect the <code class="language-plaintext highlighter-rouge">dataset_1</code> will be the center!!!</li> <li>My NVIDIA GTX 4060 isn’t enough to train AI, I should better use company’s server :&gt;</li> </ul> <h2 id="future-action">Future action</h2> <ul> <li>I need to generalize the code to let graphing in large number, not only 3 models.</li> <li>Calculate and visualize <strong>Jaccard Index</strong> graph.</li> <li><code class="language-plaintext highlighter-rouge">dataset_2</code> seems more legit, I think I will fine-tune <code class="language-plaintext highlighter-rouge">miniModel_2</code> first.</li> </ul>]]></content><author><name></name></author><category term="Linh-the-Engineer"/><category term="cse"/><category term="ml"/><category term="gom"/><category term="english"/><summary type="html"><![CDATA[the results and reflection of cosine similarity graph and first attempt to fine-tune]]></summary></entry></feed>